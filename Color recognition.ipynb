{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem Statement :** The purpose of this project is to classify colors, there are 10 different images with 20 images for each colors in the train set and 5 images for each colors in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from  torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading  the datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "compose = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor() ])\n",
    "train = ImageFolder(root=r'C:\\Users\\jeremiah\\Desktop\\colors\\train', transform = compose)\n",
    "test = ImageFolder(root=r'C:\\Users\\jeremiah\\Desktop\\colors\\test', transform = compose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train ,shuffle = True, batch_size = 50) \n",
    "test_loader = DataLoader(test ,shuffle = True, batch_size = 50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data, label = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "literal_label = os.listdir(r'C:\\Users\\jeremiah\\Desktop\\colors\\train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFMAAABgCAYAAABhXE4DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAEkklEQVR4nO2cS2gdZRTHf3/TVqpVqfhKTR8qXRhcRI1VcCOIUBSpLgSzkIJCXFgfoGDrQqsrN7oVolaLCFKoYBeVqkVQN7ZBajUN1drUNhpqfdFakJp6XMwXSONNMzdzZu6d5vzgcr8738w3J7/M437DuUdmRuDDea0O4FwiZDoSMh0JmY6ETEdCpiNzRqakOySNlrmPOSOzCmorU9K8VscwlVrJlHRI0rOS9gInJS2TtFXSMUkjkp6YtO5CSW9L+kPSPuCWsuNru/9uDvqAe4Dfgc+AD9KyLuATSfvNbAfwAnBdel0IfFh6ZGZWmxdwCHg4tW8FDk/p3wC8ldoHgdWT+vqB0TLjq+OReSS9LweWSPpzUl8H8HlqL5m0LsCPZQdWR5kTj7mOACNmtnKa9caApcBQ+rys7MBqdQOawi7geLohLZTUIekGSRM3mi3ABkmLJXUBj5cdUG1lmtlp4F6gBxgBfgXeAC5Jq7xIdmqPAB8B75Qdk+LhsB+1PTLbkZDpSCGZklZL2i/pgKT1XkHVlVlfMyV1AN8BdwGjwG6gz8z2+YVXL4ocmauAA2Z20MxOAe8Ba3zCqidFvrRfzZkzjFGyKd4ZSOonm8pxPh03X8UFBXbZen7jb07YKTXqKyKz0YD/u2aY2QAwALBCF9vz81YV2GXreWl817R9RU7zUbLp2gRdwM8Fxqs9RWTuBlZKukbSAuBBYJtPWPVk1qe5mY1LWgfsIHtas8nMhmbY7Jym0FMjM9sObHeKpfbEDMiRkOlIyHQkZDoSMh0JmY6ETEdCpiMh05GQ6UjIdCRkOhIyHQmZjoRMR0KmIyHTkZDpSMh0JGQ6EjIdCZmOzChT0lJJn0oaljQk6cm0/FJJH0v6Pr0vLj/c9ibPkTkOPG1m1wO3AY9J6gbWAzvTrx12ps9zmhllmtmYmX2V2ieAYbIMuDXA5rTaZuC+soKsC01dMyWtAG4EvgSuNLMxyIQDV0yzTb+kQUmDf/FPsWjbnNwyJS0CtgJPmdnxvNuZ2YCZ9ZpZ7yLmzybG2pBLpqT5ZCLfNbP30+KjkjpTfyfwSzkh1oc8d3MBbwLDZvbqpK5twNrUXkv269o5TZ4suNuBh4BvJO1Jy54DXga2SHoEOAw8UE6I9WFGmWb2BY1TrgHu9A2n3sQMyJGQ6UjIdCRkOhIyHQmZjoRMR0KmIyHTkZDpSMh0JGQ6UmkpHknHgJNkNYjajcvIF9dyM7u8UUfldY0kDZpZb6U7zYFHXHGaOxIyHWmFzIEW7DMPheOKWnCOxGnuSGUy26XU2VlypzZK+knSnvS6u+nBK6oV3AH8AFwLLAC+BrpbVLe4E7gptS8iK8HWDWwEnikydlVHZtuUOjtL7lRhqpLZqNSZyx9QhCm5UwDrJO2VtGk2KZJVycxV6qxKGuROvUZW072HrPjzK82OWZXMtip11ih3ysyOmtlpM/sXeJ3s0tQUVclsm1Jn0+VOTSShJe4Hvm127ErqtLdZqbPpcqf6JPWQXX4OAY82O3DMgByJGZAjIdORkOlIyHQkZDoSMh0JmY6ETEf+A5kZ7W1g/f1WAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3,3))\n",
    "for i in range(3): \n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.imshow(img_data[i].permute(1,2,0))\n",
    "    plt.title(literal_label[label[i]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ImageClassificationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageClassificationModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64*4*4, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 10)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        #input: 3 x 32 x 32\n",
    "        out = self.conv1(xb)\n",
    "        out = F.relu(out)\n",
    "        out = self.pool(out)\n",
    "        #output: 16 x 16 x 16\n",
    "        out = self.pool(F.relu(self.conv2(out)))\n",
    "#       #output: 32 x 8 x 8\n",
    "        out = self.pool(F.relu(self.conv3(out)))\n",
    "        #output: 64 x 4 x 4\n",
    "        out = out.view(-1, 64*4*4)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImageClassificationModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 / Batch 0 : Loss : 2.306922435760498 and Accuracy 8.0%\n",
      "Epoch : 0 / Batch 1 : Loss : 2.297960042953491 and Accuracy 6.0%\n",
      "Epoch : 0 / Batch 2 : Loss : 2.312845468521118 and Accuracy 2.0%\n",
      "Epoch : 0 / Batch 3 : Loss : 2.259375810623169 and Accuracy 16.0%\n",
      "Epoch : 1 / Batch 0 : Loss : 2.2691054344177246 and Accuracy 12.0%\n",
      "Epoch : 1 / Batch 1 : Loss : 2.219604015350342 and Accuracy 18.0%\n",
      "Epoch : 1 / Batch 2 : Loss : 2.073908567428589 and Accuracy 34.0%\n",
      "Epoch : 1 / Batch 3 : Loss : 2.052565097808838 and Accuracy 24.0%\n",
      "Epoch : 2 / Batch 0 : Loss : 2.122995138168335 and Accuracy 18.0%\n",
      "Epoch : 2 / Batch 1 : Loss : 1.872749924659729 and Accuracy 28.0%\n",
      "Epoch : 2 / Batch 2 : Loss : 1.7590281963348389 and Accuracy 24.0%\n",
      "Epoch : 2 / Batch 3 : Loss : 1.8154189586639404 and Accuracy 40.0%\n",
      "Epoch : 3 / Batch 0 : Loss : 1.6570022106170654 and Accuracy 38.0%\n",
      "Epoch : 3 / Batch 1 : Loss : 1.4681822061538696 and Accuracy 42.0%\n",
      "Epoch : 3 / Batch 2 : Loss : 1.566595435142517 and Accuracy 36.0%\n",
      "Epoch : 3 / Batch 3 : Loss : 1.4322680234909058 and Accuracy 44.0%\n",
      "Epoch : 4 / Batch 0 : Loss : 1.3566946983337402 and Accuracy 56.0%\n",
      "Epoch : 4 / Batch 1 : Loss : 1.1285200119018555 and Accuracy 68.0%\n",
      "Epoch : 4 / Batch 2 : Loss : 1.2089251279830933 and Accuracy 56.0%\n",
      "Epoch : 4 / Batch 3 : Loss : 1.167677640914917 and Accuracy 50.0%\n",
      "Epoch : 5 / Batch 0 : Loss : 0.8377429246902466 and Accuracy 70.0%\n",
      "Epoch : 5 / Batch 1 : Loss : 1.2242176532745361 and Accuracy 40.0%\n",
      "Epoch : 5 / Batch 2 : Loss : 1.0817162990570068 and Accuracy 58.0%\n",
      "Epoch : 5 / Batch 3 : Loss : 1.0366398096084595 and Accuracy 66.0%\n",
      "Epoch : 6 / Batch 0 : Loss : 0.9683279395103455 and Accuracy 66.0%\n",
      "Epoch : 6 / Batch 1 : Loss : 0.860599160194397 and Accuracy 72.0%\n",
      "Epoch : 6 / Batch 2 : Loss : 0.7560902237892151 and Accuracy 82.0%\n",
      "Epoch : 6 / Batch 3 : Loss : 0.9750090837478638 and Accuracy 66.0%\n",
      "Epoch : 7 / Batch 0 : Loss : 0.9284291863441467 and Accuracy 68.0%\n",
      "Epoch : 7 / Batch 1 : Loss : 0.8208718299865723 and Accuracy 68.0%\n",
      "Epoch : 7 / Batch 2 : Loss : 0.8939722180366516 and Accuracy 60.000003814697266%\n",
      "Epoch : 7 / Batch 3 : Loss : 0.6182559728622437 and Accuracy 78.0%\n",
      "Epoch : 8 / Batch 0 : Loss : 0.7166174054145813 and Accuracy 70.0%\n",
      "Epoch : 8 / Batch 1 : Loss : 0.6106059551239014 and Accuracy 74.0%\n",
      "Epoch : 8 / Batch 2 : Loss : 0.6835138201713562 and Accuracy 72.0%\n",
      "Epoch : 8 / Batch 3 : Loss : 0.758065938949585 and Accuracy 70.0%\n",
      "Epoch : 9 / Batch 0 : Loss : 0.5635244250297546 and Accuracy 74.0%\n",
      "Epoch : 9 / Batch 1 : Loss : 0.6916470527648926 and Accuracy 74.0%\n",
      "Epoch : 9 / Batch 2 : Loss : 0.5633903741836548 and Accuracy 80.0%\n",
      "Epoch : 9 / Batch 3 : Loss : 0.575300931930542 and Accuracy 78.0%\n",
      "Epoch : 10 / Batch 0 : Loss : 0.30557116866111755 and Accuracy 90.0%\n",
      "Epoch : 10 / Batch 1 : Loss : 0.5051336884498596 and Accuracy 80.0%\n",
      "Epoch : 10 / Batch 2 : Loss : 1.0867596864700317 and Accuracy 64.0%\n",
      "Epoch : 10 / Batch 3 : Loss : 0.6812348961830139 and Accuracy 76.0%\n",
      "Epoch : 11 / Batch 0 : Loss : 0.5714786648750305 and Accuracy 76.0%\n",
      "Epoch : 11 / Batch 1 : Loss : 0.8874530792236328 and Accuracy 66.0%\n",
      "Epoch : 11 / Batch 2 : Loss : 0.48393726348876953 and Accuracy 80.0%\n",
      "Epoch : 11 / Batch 3 : Loss : 0.7000665068626404 and Accuracy 74.0%\n",
      "Epoch : 12 / Batch 0 : Loss : 0.6033923625946045 and Accuracy 72.0%\n",
      "Epoch : 12 / Batch 1 : Loss : 0.5955525040626526 and Accuracy 74.0%\n",
      "Epoch : 12 / Batch 2 : Loss : 0.42583930492401123 and Accuracy 82.0%\n",
      "Epoch : 12 / Batch 3 : Loss : 0.6573012471199036 and Accuracy 78.0%\n",
      "Epoch : 13 / Batch 0 : Loss : 0.7132692933082581 and Accuracy 70.0%\n",
      "Epoch : 13 / Batch 1 : Loss : 0.3953879177570343 and Accuracy 86.0%\n",
      "Epoch : 13 / Batch 2 : Loss : 0.8601490259170532 and Accuracy 74.0%\n",
      "Epoch : 13 / Batch 3 : Loss : 0.5865541696548462 and Accuracy 78.0%\n",
      "Epoch : 14 / Batch 0 : Loss : 0.5202768445014954 and Accuracy 74.0%\n",
      "Epoch : 14 / Batch 1 : Loss : 0.4767659306526184 and Accuracy 82.0%\n",
      "Epoch : 14 / Batch 2 : Loss : 0.4652588963508606 and Accuracy 88.0%\n",
      "Epoch : 14 / Batch 3 : Loss : 0.6064866781234741 and Accuracy 80.0%\n",
      "Epoch : 15 / Batch 0 : Loss : 0.43148916959762573 and Accuracy 88.0%\n",
      "Epoch : 15 / Batch 1 : Loss : 0.5414184927940369 and Accuracy 76.0%\n",
      "Epoch : 15 / Batch 2 : Loss : 0.3615844249725342 and Accuracy 86.0%\n",
      "Epoch : 15 / Batch 3 : Loss : 0.5213284492492676 and Accuracy 82.0%\n",
      "Epoch : 16 / Batch 0 : Loss : 0.5393239855766296 and Accuracy 82.0%\n",
      "Epoch : 16 / Batch 1 : Loss : 0.41954463720321655 and Accuracy 82.0%\n",
      "Epoch : 16 / Batch 2 : Loss : 0.2502899467945099 and Accuracy 96.0%\n",
      "Epoch : 16 / Batch 3 : Loss : 0.3308641314506531 and Accuracy 88.0%\n",
      "Epoch : 17 / Batch 0 : Loss : 0.35558605194091797 and Accuracy 86.0%\n",
      "Epoch : 17 / Batch 1 : Loss : 0.48144444823265076 and Accuracy 80.0%\n",
      "Epoch : 17 / Batch 2 : Loss : 0.4272497594356537 and Accuracy 82.0%\n",
      "Epoch : 17 / Batch 3 : Loss : 0.28362447023391724 and Accuracy 90.0%\n",
      "Epoch : 18 / Batch 0 : Loss : 0.2852117717266083 and Accuracy 90.0%\n",
      "Epoch : 18 / Batch 1 : Loss : 0.37729907035827637 and Accuracy 84.0%\n",
      "Epoch : 18 / Batch 2 : Loss : 0.23462262749671936 and Accuracy 92.0%\n",
      "Epoch : 18 / Batch 3 : Loss : 0.5617761015892029 and Accuracy 80.0%\n",
      "Epoch : 19 / Batch 0 : Loss : 0.3215884864330292 and Accuracy 94.0%\n",
      "Epoch : 19 / Batch 1 : Loss : 0.3437056839466095 and Accuracy 88.0%\n",
      "Epoch : 19 / Batch 2 : Loss : 0.4723120927810669 and Accuracy 82.0%\n",
      "Epoch : 19 / Batch 3 : Loss : 0.24512678384780884 and Accuracy 94.0%\n",
      "Epoch : 20 / Batch 0 : Loss : 0.22133250534534454 and Accuracy 94.0%\n",
      "Epoch : 20 / Batch 1 : Loss : 0.3791762590408325 and Accuracy 84.0%\n",
      "Epoch : 20 / Batch 2 : Loss : 0.20858295261859894 and Accuracy 94.0%\n",
      "Epoch : 20 / Batch 3 : Loss : 0.2911441922187805 and Accuracy 86.0%\n",
      "Epoch : 21 / Batch 0 : Loss : 0.23949868977069855 and Accuracy 94.0%\n",
      "Epoch : 21 / Batch 1 : Loss : 0.14726822078227997 and Accuracy 92.0%\n",
      "Epoch : 21 / Batch 2 : Loss : 0.3388385474681854 and Accuracy 90.0%\n",
      "Epoch : 21 / Batch 3 : Loss : 0.44644394516944885 and Accuracy 82.0%\n",
      "Epoch : 22 / Batch 0 : Loss : 0.3370025157928467 and Accuracy 86.0%\n",
      "Epoch : 22 / Batch 1 : Loss : 0.3024103045463562 and Accuracy 92.0%\n",
      "Epoch : 22 / Batch 2 : Loss : 0.24958842992782593 and Accuracy 90.0%\n",
      "Epoch : 22 / Batch 3 : Loss : 0.17351558804512024 and Accuracy 94.0%\n",
      "Epoch : 23 / Batch 0 : Loss : 0.27052733302116394 and Accuracy 90.0%\n",
      "Epoch : 23 / Batch 1 : Loss : 0.2752467095851898 and Accuracy 86.0%\n",
      "Epoch : 23 / Batch 2 : Loss : 0.12216372787952423 and Accuracy 98.0%\n",
      "Epoch : 23 / Batch 3 : Loss : 0.7525015473365784 and Accuracy 70.0%\n",
      "Epoch : 24 / Batch 0 : Loss : 0.2806442677974701 and Accuracy 92.0%\n",
      "Epoch : 24 / Batch 1 : Loss : 0.251275897026062 and Accuracy 90.0%\n",
      "Epoch : 24 / Batch 2 : Loss : 0.1792384684085846 and Accuracy 96.0%\n",
      "Epoch : 24 / Batch 3 : Loss : 0.345659077167511 and Accuracy 90.0%\n",
      "Epoch : 25 / Batch 0 : Loss : 0.2624523639678955 and Accuracy 90.0%\n",
      "Epoch : 25 / Batch 1 : Loss : 0.16773469746112823 and Accuracy 90.0%\n",
      "Epoch : 25 / Batch 2 : Loss : 0.17672838270664215 and Accuracy 96.0%\n",
      "Epoch : 25 / Batch 3 : Loss : 0.15016742050647736 and Accuracy 92.0%\n",
      "Epoch : 26 / Batch 0 : Loss : 0.3303722143173218 and Accuracy 86.0%\n",
      "Epoch : 26 / Batch 1 : Loss : 0.13361500203609467 and Accuracy 96.0%\n",
      "Epoch : 26 / Batch 2 : Loss : 0.1344907283782959 and Accuracy 94.0%\n",
      "Epoch : 26 / Batch 3 : Loss : 0.21599240601062775 and Accuracy 88.0%\n",
      "Epoch : 27 / Batch 0 : Loss : 0.16346101462841034 and Accuracy 94.0%\n",
      "Epoch : 27 / Batch 1 : Loss : 0.15104742348194122 and Accuracy 94.0%\n",
      "Epoch : 27 / Batch 2 : Loss : 0.11430028825998306 and Accuracy 94.0%\n",
      "Epoch : 27 / Batch 3 : Loss : 0.2452808916568756 and Accuracy 90.0%\n",
      "Epoch : 28 / Batch 0 : Loss : 0.13035926222801208 and Accuracy 96.0%\n",
      "Epoch : 28 / Batch 1 : Loss : 0.09900540113449097 and Accuracy 96.0%\n",
      "Epoch : 28 / Batch 2 : Loss : 0.13349832594394684 and Accuracy 96.0%\n",
      "Epoch : 28 / Batch 3 : Loss : 0.14941903948783875 and Accuracy 96.0%\n",
      "Epoch : 29 / Batch 0 : Loss : 0.1461511105298996 and Accuracy 94.0%\n",
      "Epoch : 29 / Batch 1 : Loss : 0.180326446890831 and Accuracy 90.0%\n",
      "Epoch : 29 / Batch 2 : Loss : 0.13424183428287506 and Accuracy 96.0%\n",
      "Epoch : 29 / Batch 3 : Loss : 0.18016494810581207 and Accuracy 92.0%\n",
      "Epoch : 30 / Batch 0 : Loss : 0.09695059061050415 and Accuracy 96.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 30 / Batch 1 : Loss : 0.1335277259349823 and Accuracy 92.0%\n",
      "Epoch : 30 / Batch 2 : Loss : 0.07116787135601044 and Accuracy 96.0%\n",
      "Epoch : 30 / Batch 3 : Loss : 0.10913529992103577 and Accuracy 94.0%\n",
      "Epoch : 31 / Batch 0 : Loss : 0.0537610799074173 and Accuracy 100.0%\n",
      "Epoch : 31 / Batch 1 : Loss : 0.2663397490978241 and Accuracy 86.0%\n",
      "Epoch : 31 / Batch 2 : Loss : 0.27174654603004456 and Accuracy 88.0%\n",
      "Epoch : 31 / Batch 3 : Loss : 0.07667384296655655 and Accuracy 98.0%\n",
      "Epoch : 32 / Batch 0 : Loss : 0.2522253394126892 and Accuracy 92.0%\n",
      "Epoch : 32 / Batch 1 : Loss : 0.0746789202094078 and Accuracy 100.0%\n",
      "Epoch : 32 / Batch 2 : Loss : 0.054741859436035156 and Accuracy 100.0%\n",
      "Epoch : 32 / Batch 3 : Loss : 0.17266084253787994 and Accuracy 94.0%\n",
      "Epoch : 33 / Batch 0 : Loss : 0.11696921288967133 and Accuracy 94.0%\n",
      "Epoch : 33 / Batch 1 : Loss : 0.2011350840330124 and Accuracy 94.0%\n",
      "Epoch : 33 / Batch 2 : Loss : 0.10858318954706192 and Accuracy 96.0%\n",
      "Epoch : 33 / Batch 3 : Loss : 0.03566567599773407 and Accuracy 98.0%\n",
      "Epoch : 34 / Batch 0 : Loss : 0.12882402539253235 and Accuracy 96.0%\n",
      "Epoch : 34 / Batch 1 : Loss : 0.14568981528282166 and Accuracy 94.0%\n",
      "Epoch : 34 / Batch 2 : Loss : 0.16305039823055267 and Accuracy 94.0%\n",
      "Epoch : 34 / Batch 3 : Loss : 0.2084023505449295 and Accuracy 94.0%\n",
      "Epoch : 35 / Batch 0 : Loss : 0.12298495322465897 and Accuracy 96.0%\n",
      "Epoch : 35 / Batch 1 : Loss : 0.08796562999486923 and Accuracy 98.0%\n",
      "Epoch : 35 / Batch 2 : Loss : 0.13251252472400665 and Accuracy 94.0%\n",
      "Epoch : 35 / Batch 3 : Loss : 0.21586552262306213 and Accuracy 86.0%\n",
      "Epoch : 36 / Batch 0 : Loss : 0.16238254308700562 and Accuracy 90.0%\n",
      "Epoch : 36 / Batch 1 : Loss : 0.19923478364944458 and Accuracy 94.0%\n",
      "Epoch : 36 / Batch 2 : Loss : 0.2387395054101944 and Accuracy 94.0%\n",
      "Epoch : 36 / Batch 3 : Loss : 0.057341307401657104 and Accuracy 98.0%\n",
      "Epoch : 37 / Batch 0 : Loss : 0.06229989975690842 and Accuracy 98.0%\n",
      "Epoch : 37 / Batch 1 : Loss : 0.06445856392383575 and Accuracy 98.0%\n",
      "Epoch : 37 / Batch 2 : Loss : 0.1769106239080429 and Accuracy 92.0%\n",
      "Epoch : 37 / Batch 3 : Loss : 0.3051833212375641 and Accuracy 94.0%\n",
      "Epoch : 38 / Batch 0 : Loss : 0.13692915439605713 and Accuracy 92.0%\n",
      "Epoch : 38 / Batch 1 : Loss : 0.22408613562583923 and Accuracy 90.0%\n",
      "Epoch : 38 / Batch 2 : Loss : 0.19713740050792694 and Accuracy 88.0%\n",
      "Epoch : 38 / Batch 3 : Loss : 0.2506069839000702 and Accuracy 90.0%\n",
      "Epoch : 39 / Batch 0 : Loss : 0.10563161969184875 and Accuracy 98.0%\n",
      "Epoch : 39 / Batch 1 : Loss : 0.06402042508125305 and Accuracy 96.0%\n",
      "Epoch : 39 / Batch 2 : Loss : 0.16002216935157776 and Accuracy 92.0%\n",
      "Epoch : 39 / Batch 3 : Loss : 0.5015271902084351 and Accuracy 84.0%\n",
      "Epoch : 40 / Batch 0 : Loss : 0.238310769200325 and Accuracy 92.0%\n",
      "Epoch : 40 / Batch 1 : Loss : 0.22870996594429016 and Accuracy 92.0%\n",
      "Epoch : 40 / Batch 2 : Loss : 0.1500326246023178 and Accuracy 92.0%\n",
      "Epoch : 40 / Batch 3 : Loss : 0.2091011255979538 and Accuracy 92.0%\n",
      "Epoch : 41 / Batch 0 : Loss : 0.25854209065437317 and Accuracy 88.0%\n",
      "Epoch : 41 / Batch 1 : Loss : 0.1749366968870163 and Accuracy 90.0%\n",
      "Epoch : 41 / Batch 2 : Loss : 0.11106464266777039 and Accuracy 94.0%\n",
      "Epoch : 41 / Batch 3 : Loss : 0.17541499435901642 and Accuracy 98.0%\n",
      "Epoch : 42 / Batch 0 : Loss : 0.30172890424728394 and Accuracy 94.0%\n",
      "Epoch : 42 / Batch 1 : Loss : 0.020960606634616852 and Accuracy 100.0%\n",
      "Epoch : 42 / Batch 2 : Loss : 0.13814879953861237 and Accuracy 96.0%\n",
      "Epoch : 42 / Batch 3 : Loss : 0.2827898859977722 and Accuracy 90.0%\n",
      "Epoch : 43 / Batch 0 : Loss : 0.10119502246379852 and Accuracy 96.0%\n",
      "Epoch : 43 / Batch 1 : Loss : 0.08294890075922012 and Accuracy 94.0%\n",
      "Epoch : 43 / Batch 2 : Loss : 0.0501776747405529 and Accuracy 98.0%\n",
      "Epoch : 43 / Batch 3 : Loss : 0.08465442806482315 and Accuracy 96.0%\n",
      "Epoch : 44 / Batch 0 : Loss : 0.08852662891149521 and Accuracy 96.0%\n",
      "Epoch : 44 / Batch 1 : Loss : 0.038196414709091187 and Accuracy 98.0%\n",
      "Epoch : 44 / Batch 2 : Loss : 0.08150722831487656 and Accuracy 96.0%\n",
      "Epoch : 44 / Batch 3 : Loss : 0.2887520492076874 and Accuracy 90.0%\n",
      "Epoch : 45 / Batch 0 : Loss : 0.14769954979419708 and Accuracy 94.0%\n",
      "Epoch : 45 / Batch 1 : Loss : 0.07972060889005661 and Accuracy 96.0%\n",
      "Epoch : 45 / Batch 2 : Loss : 0.06988877058029175 and Accuracy 98.0%\n",
      "Epoch : 45 / Batch 3 : Loss : 0.05226995050907135 and Accuracy 100.0%\n",
      "Epoch : 46 / Batch 0 : Loss : 0.04383445158600807 and Accuracy 100.0%\n",
      "Epoch : 46 / Batch 1 : Loss : 0.05423438549041748 and Accuracy 98.0%\n",
      "Epoch : 46 / Batch 2 : Loss : 0.07760170847177505 and Accuracy 96.0%\n",
      "Epoch : 46 / Batch 3 : Loss : 0.14857621490955353 and Accuracy 94.0%\n",
      "Epoch : 47 / Batch 0 : Loss : 0.07234694808721542 and Accuracy 96.0%\n",
      "Epoch : 47 / Batch 1 : Loss : 0.045884374529123306 and Accuracy 100.0%\n",
      "Epoch : 47 / Batch 2 : Loss : 0.055504512041807175 and Accuracy 98.0%\n",
      "Epoch : 47 / Batch 3 : Loss : 0.06047757714986801 and Accuracy 98.0%\n",
      "Epoch : 48 / Batch 0 : Loss : 0.06243375316262245 and Accuracy 96.0%\n",
      "Epoch : 48 / Batch 1 : Loss : 0.13257616758346558 and Accuracy 94.0%\n",
      "Epoch : 48 / Batch 2 : Loss : 0.09095150232315063 and Accuracy 98.0%\n",
      "Epoch : 48 / Batch 3 : Loss : 0.02409721538424492 and Accuracy 100.0%\n",
      "Epoch : 49 / Batch 0 : Loss : 0.03298582136631012 and Accuracy 98.0%\n",
      "Epoch : 49 / Batch 1 : Loss : 0.06040750816464424 and Accuracy 98.0%\n",
      "Epoch : 49 / Batch 2 : Loss : 0.028933387249708176 and Accuracy 100.0%\n",
      "Epoch : 49 / Batch 3 : Loss : 0.012678119353950024 and Accuracy 100.0%\n",
      "Epoch : 50 / Batch 0 : Loss : 0.0100072231143713 and Accuracy 100.0%\n",
      "Epoch : 50 / Batch 1 : Loss : 0.08112302422523499 and Accuracy 96.0%\n",
      "Epoch : 50 / Batch 2 : Loss : 0.03553248941898346 and Accuracy 98.0%\n",
      "Epoch : 50 / Batch 3 : Loss : 0.04889662191271782 and Accuracy 100.0%\n",
      "Epoch : 51 / Batch 0 : Loss : 0.06057625263929367 and Accuracy 98.0%\n",
      "Epoch : 51 / Batch 1 : Loss : 0.012228813022375107 and Accuracy 100.0%\n",
      "Epoch : 51 / Batch 2 : Loss : 0.042113013565540314 and Accuracy 98.0%\n",
      "Epoch : 51 / Batch 3 : Loss : 0.09545677900314331 and Accuracy 98.0%\n",
      "Epoch : 52 / Batch 0 : Loss : 0.028688302263617516 and Accuracy 100.0%\n",
      "Epoch : 52 / Batch 1 : Loss : 0.019629068672657013 and Accuracy 100.0%\n",
      "Epoch : 52 / Batch 2 : Loss : 0.044339850544929504 and Accuracy 98.0%\n",
      "Epoch : 52 / Batch 3 : Loss : 0.1453893780708313 and Accuracy 92.0%\n",
      "Epoch : 53 / Batch 0 : Loss : 0.004818124696612358 and Accuracy 100.0%\n",
      "Epoch : 53 / Batch 1 : Loss : 0.2638446092605591 and Accuracy 92.0%\n",
      "Epoch : 53 / Batch 2 : Loss : 0.011916602961719036 and Accuracy 100.0%\n",
      "Epoch : 53 / Batch 3 : Loss : 0.23230935633182526 and Accuracy 96.0%\n",
      "Epoch : 54 / Batch 0 : Loss : 0.016422700136899948 and Accuracy 100.0%\n",
      "Epoch : 54 / Batch 1 : Loss : 0.1321343332529068 and Accuracy 90.0%\n",
      "Epoch : 54 / Batch 2 : Loss : 0.054957590997219086 and Accuracy 96.0%\n",
      "Epoch : 54 / Batch 3 : Loss : 0.08431842178106308 and Accuracy 98.0%\n",
      "Epoch : 55 / Batch 0 : Loss : 0.3542366325855255 and Accuracy 90.0%\n",
      "Epoch : 55 / Batch 1 : Loss : 0.022292830049991608 and Accuracy 100.0%\n",
      "Epoch : 55 / Batch 2 : Loss : 0.15812359750270844 and Accuracy 94.0%\n",
      "Epoch : 55 / Batch 3 : Loss : 0.008969184942543507 and Accuracy 100.0%\n",
      "Epoch : 56 / Batch 0 : Loss : 0.17594365775585175 and Accuracy 92.0%\n",
      "Epoch : 56 / Batch 1 : Loss : 0.2868175804615021 and Accuracy 90.0%\n",
      "Epoch : 56 / Batch 2 : Loss : 0.02652028761804104 and Accuracy 98.0%\n",
      "Epoch : 56 / Batch 3 : Loss : 0.08397834748029709 and Accuracy 96.0%\n",
      "Epoch : 57 / Batch 0 : Loss : 0.03448711335659027 and Accuracy 100.0%\n",
      "Epoch : 57 / Batch 1 : Loss : 0.12345533072948456 and Accuracy 96.0%\n",
      "Epoch : 57 / Batch 2 : Loss : 0.05807233229279518 and Accuracy 100.0%\n",
      "Epoch : 57 / Batch 3 : Loss : 0.13340240716934204 and Accuracy 92.0%\n",
      "Epoch : 58 / Batch 0 : Loss : 0.07951030135154724 and Accuracy 96.0%\n",
      "Epoch : 58 / Batch 1 : Loss : 0.09543929994106293 and Accuracy 94.0%\n",
      "Epoch : 58 / Batch 2 : Loss : 0.048997774720191956 and Accuracy 100.0%\n",
      "Epoch : 58 / Batch 3 : Loss : 0.07530998438596725 and Accuracy 96.0%\n",
      "Epoch : 59 / Batch 0 : Loss : 0.07516645640134811 and Accuracy 96.0%\n",
      "Epoch : 59 / Batch 1 : Loss : 0.14824829995632172 and Accuracy 92.0%\n",
      "Epoch : 59 / Batch 2 : Loss : 0.07133989036083221 and Accuracy 96.0%\n",
      "Epoch : 59 / Batch 3 : Loss : 0.03358839452266693 and Accuracy 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 60 / Batch 0 : Loss : 0.0701017826795578 and Accuracy 98.0%\n",
      "Epoch : 60 / Batch 1 : Loss : 0.08823530375957489 and Accuracy 94.0%\n",
      "Epoch : 60 / Batch 2 : Loss : 0.07574525475502014 and Accuracy 98.0%\n",
      "Epoch : 60 / Batch 3 : Loss : 0.023758621886372566 and Accuracy 100.0%\n",
      "Epoch : 61 / Batch 0 : Loss : 0.019988704472780228 and Accuracy 100.0%\n",
      "Epoch : 61 / Batch 1 : Loss : 0.09724585711956024 and Accuracy 96.0%\n",
      "Epoch : 61 / Batch 2 : Loss : 0.045560069382190704 and Accuracy 96.0%\n",
      "Epoch : 61 / Batch 3 : Loss : 0.030297856777906418 and Accuracy 100.0%\n",
      "Epoch : 62 / Batch 0 : Loss : 0.03325113281607628 and Accuracy 100.0%\n",
      "Epoch : 62 / Batch 1 : Loss : 0.07806474715471268 and Accuracy 96.0%\n",
      "Epoch : 62 / Batch 2 : Loss : 0.04040052369236946 and Accuracy 98.0%\n",
      "Epoch : 62 / Batch 3 : Loss : 0.023660019040107727 and Accuracy 100.0%\n",
      "Epoch : 63 / Batch 0 : Loss : 0.03705710917711258 and Accuracy 98.0%\n",
      "Epoch : 63 / Batch 1 : Loss : 0.02330850623548031 and Accuracy 98.0%\n",
      "Epoch : 63 / Batch 2 : Loss : 0.026487233117222786 and Accuracy 98.0%\n",
      "Epoch : 63 / Batch 3 : Loss : 0.07217563688755035 and Accuracy 96.0%\n",
      "Epoch : 64 / Batch 0 : Loss : 0.04141518473625183 and Accuracy 100.0%\n",
      "Epoch : 64 / Batch 1 : Loss : 0.003970286343246698 and Accuracy 100.0%\n",
      "Epoch : 64 / Batch 2 : Loss : 0.00900984089821577 and Accuracy 100.0%\n",
      "Epoch : 64 / Batch 3 : Loss : 0.09427332133054733 and Accuracy 92.0%\n",
      "Epoch : 65 / Batch 0 : Loss : 0.04118221253156662 and Accuracy 98.0%\n",
      "Epoch : 65 / Batch 1 : Loss : 0.013609073124825954 and Accuracy 100.0%\n",
      "Epoch : 65 / Batch 2 : Loss : 0.15438462793827057 and Accuracy 94.0%\n",
      "Epoch : 65 / Batch 3 : Loss : 0.003890407271683216 and Accuracy 100.0%\n",
      "Epoch : 66 / Batch 0 : Loss : 0.006366467569023371 and Accuracy 100.0%\n",
      "Epoch : 66 / Batch 1 : Loss : 0.020375382155179977 and Accuracy 98.0%\n",
      "Epoch : 66 / Batch 2 : Loss : 0.040125325322151184 and Accuracy 98.0%\n",
      "Epoch : 66 / Batch 3 : Loss : 0.064201720058918 and Accuracy 98.0%\n",
      "Epoch : 67 / Batch 0 : Loss : 0.022429106757044792 and Accuracy 100.0%\n",
      "Epoch : 67 / Batch 1 : Loss : 0.06965367496013641 and Accuracy 96.0%\n",
      "Epoch : 67 / Batch 2 : Loss : 0.020923279225826263 and Accuracy 100.0%\n",
      "Epoch : 67 / Batch 3 : Loss : 0.011840845458209515 and Accuracy 100.0%\n",
      "Epoch : 68 / Batch 0 : Loss : 0.04184645041823387 and Accuracy 98.0%\n",
      "Epoch : 68 / Batch 1 : Loss : 0.06261822581291199 and Accuracy 96.0%\n",
      "Epoch : 68 / Batch 2 : Loss : 0.027538245543837547 and Accuracy 98.0%\n",
      "Epoch : 68 / Batch 3 : Loss : 0.03746380656957626 and Accuracy 98.0%\n",
      "Epoch : 69 / Batch 0 : Loss : 0.02825571969151497 and Accuracy 100.0%\n",
      "Epoch : 69 / Batch 1 : Loss : 0.01803080178797245 and Accuracy 100.0%\n",
      "Epoch : 69 / Batch 2 : Loss : 0.0053797573782503605 and Accuracy 100.0%\n",
      "Epoch : 69 / Batch 3 : Loss : 0.07430526614189148 and Accuracy 96.0%\n",
      "Epoch : 70 / Batch 0 : Loss : 0.06484755128622055 and Accuracy 98.0%\n",
      "Epoch : 70 / Batch 1 : Loss : 0.003580919001251459 and Accuracy 100.0%\n",
      "Epoch : 70 / Batch 2 : Loss : 0.063668392598629 and Accuracy 98.0%\n",
      "Epoch : 70 / Batch 3 : Loss : 0.30415433645248413 and Accuracy 92.0%\n",
      "Epoch : 71 / Batch 0 : Loss : 0.0028889914974570274 and Accuracy 100.0%\n",
      "Epoch : 71 / Batch 1 : Loss : 0.05993839353322983 and Accuracy 98.0%\n",
      "Epoch : 71 / Batch 2 : Loss : 0.03130992874503136 and Accuracy 100.0%\n",
      "Epoch : 71 / Batch 3 : Loss : 0.06180967763066292 and Accuracy 96.0%\n",
      "Epoch : 72 / Batch 0 : Loss : 0.028074879199266434 and Accuracy 100.0%\n",
      "Epoch : 72 / Batch 1 : Loss : 0.0483400858938694 and Accuracy 96.0%\n",
      "Epoch : 72 / Batch 2 : Loss : 0.04408375173807144 and Accuracy 98.0%\n",
      "Epoch : 72 / Batch 3 : Loss : 0.06931290775537491 and Accuracy 96.0%\n",
      "Epoch : 73 / Batch 0 : Loss : 0.008528976701200008 and Accuracy 100.0%\n",
      "Epoch : 73 / Batch 1 : Loss : 0.10499030351638794 and Accuracy 98.0%\n",
      "Epoch : 73 / Batch 2 : Loss : 0.19826318323612213 and Accuracy 94.0%\n",
      "Epoch : 73 / Batch 3 : Loss : 0.06558933109045029 and Accuracy 96.0%\n",
      "Epoch : 74 / Batch 0 : Loss : 0.007671626750379801 and Accuracy 100.0%\n",
      "Epoch : 74 / Batch 1 : Loss : 0.042663250118494034 and Accuracy 98.0%\n",
      "Epoch : 74 / Batch 2 : Loss : 0.015249550342559814 and Accuracy 100.0%\n",
      "Epoch : 74 / Batch 3 : Loss : 0.17663314938545227 and Accuracy 90.0%\n",
      "Epoch : 75 / Batch 0 : Loss : 0.022707317024469376 and Accuracy 100.0%\n",
      "Epoch : 75 / Batch 1 : Loss : 0.030588772147893906 and Accuracy 98.0%\n",
      "Epoch : 75 / Batch 2 : Loss : 0.03757457807660103 and Accuracy 98.0%\n",
      "Epoch : 75 / Batch 3 : Loss : 0.05173375457525253 and Accuracy 98.0%\n",
      "Epoch : 76 / Batch 0 : Loss : 0.07239444553852081 and Accuracy 96.0%\n",
      "Epoch : 76 / Batch 1 : Loss : 0.08563663810491562 and Accuracy 96.0%\n",
      "Epoch : 76 / Batch 2 : Loss : 0.07874252647161484 and Accuracy 96.0%\n",
      "Epoch : 76 / Batch 3 : Loss : 0.039847489446401596 and Accuracy 98.0%\n",
      "Epoch : 77 / Batch 0 : Loss : 0.023973923176527023 and Accuracy 100.0%\n",
      "Epoch : 77 / Batch 1 : Loss : 0.04991880804300308 and Accuracy 98.0%\n",
      "Epoch : 77 / Batch 2 : Loss : 0.2399216592311859 and Accuracy 92.0%\n",
      "Epoch : 77 / Batch 3 : Loss : 0.008138306438922882 and Accuracy 100.0%\n",
      "Epoch : 78 / Batch 0 : Loss : 0.028350330889225006 and Accuracy 100.0%\n",
      "Epoch : 78 / Batch 1 : Loss : 0.03843015059828758 and Accuracy 100.0%\n",
      "Epoch : 78 / Batch 2 : Loss : 0.03856819495558739 and Accuracy 98.0%\n",
      "Epoch : 78 / Batch 3 : Loss : 0.08992913365364075 and Accuracy 98.0%\n",
      "Epoch : 79 / Batch 0 : Loss : 0.07341724634170532 and Accuracy 96.0%\n",
      "Epoch : 79 / Batch 1 : Loss : 0.009251081384718418 and Accuracy 100.0%\n",
      "Epoch : 79 / Batch 2 : Loss : 0.04326819255948067 and Accuracy 100.0%\n",
      "Epoch : 79 / Batch 3 : Loss : 0.08171484619379044 and Accuracy 94.0%\n",
      "Epoch : 80 / Batch 0 : Loss : 0.03229256719350815 and Accuracy 100.0%\n",
      "Epoch : 80 / Batch 1 : Loss : 0.060545023530721664 and Accuracy 98.0%\n",
      "Epoch : 80 / Batch 2 : Loss : 0.021563410758972168 and Accuracy 100.0%\n",
      "Epoch : 80 / Batch 3 : Loss : 0.009579116478562355 and Accuracy 100.0%\n",
      "Epoch : 81 / Batch 0 : Loss : 0.0439416728913784 and Accuracy 98.0%\n",
      "Epoch : 81 / Batch 1 : Loss : 0.0023564312141388655 and Accuracy 100.0%\n",
      "Epoch : 81 / Batch 2 : Loss : 0.06182415410876274 and Accuracy 98.0%\n",
      "Epoch : 81 / Batch 3 : Loss : 0.07464026659727097 and Accuracy 94.0%\n",
      "Epoch : 82 / Batch 0 : Loss : 0.022018084302544594 and Accuracy 100.0%\n",
      "Epoch : 82 / Batch 1 : Loss : 0.0661882609128952 and Accuracy 98.0%\n",
      "Epoch : 82 / Batch 2 : Loss : 0.037684641778469086 and Accuracy 98.0%\n",
      "Epoch : 82 / Batch 3 : Loss : 0.020527824759483337 and Accuracy 100.0%\n",
      "Epoch : 83 / Batch 0 : Loss : 0.02401277795433998 and Accuracy 100.0%\n",
      "Epoch : 83 / Batch 1 : Loss : 0.04648277163505554 and Accuracy 98.0%\n",
      "Epoch : 83 / Batch 2 : Loss : 0.02142644114792347 and Accuracy 100.0%\n",
      "Epoch : 83 / Batch 3 : Loss : 0.026113366708159447 and Accuracy 98.0%\n",
      "Epoch : 84 / Batch 0 : Loss : 0.01590174250304699 and Accuracy 100.0%\n",
      "Epoch : 84 / Batch 1 : Loss : 0.020206205546855927 and Accuracy 100.0%\n",
      "Epoch : 84 / Batch 2 : Loss : 0.027534767985343933 and Accuracy 100.0%\n",
      "Epoch : 84 / Batch 3 : Loss : 0.018740521743893623 and Accuracy 100.0%\n",
      "Epoch : 85 / Batch 0 : Loss : 0.01829903945326805 and Accuracy 100.0%\n",
      "Epoch : 85 / Batch 1 : Loss : 0.0029165330342948437 and Accuracy 100.0%\n",
      "Epoch : 85 / Batch 2 : Loss : 0.029126565903425217 and Accuracy 98.0%\n",
      "Epoch : 85 / Batch 3 : Loss : 0.04580339789390564 and Accuracy 98.0%\n",
      "Epoch : 86 / Batch 0 : Loss : 0.011519827879965305 and Accuracy 100.0%\n",
      "Epoch : 86 / Batch 1 : Loss : 0.00968434289097786 and Accuracy 100.0%\n",
      "Epoch : 86 / Batch 2 : Loss : 0.018481137230992317 and Accuracy 100.0%\n",
      "Epoch : 86 / Batch 3 : Loss : 0.10309641808271408 and Accuracy 94.0%\n",
      "Epoch : 87 / Batch 0 : Loss : 0.007285496219992638 and Accuracy 100.0%\n",
      "Epoch : 87 / Batch 1 : Loss : 0.2531966269016266 and Accuracy 94.0%\n",
      "Epoch : 87 / Batch 2 : Loss : 0.13861379027366638 and Accuracy 96.0%\n",
      "Epoch : 87 / Batch 3 : Loss : 0.025378607213497162 and Accuracy 98.0%\n",
      "Epoch : 88 / Batch 0 : Loss : 0.0015271907905116677 and Accuracy 100.0%\n",
      "Epoch : 88 / Batch 1 : Loss : 0.02365010231733322 and Accuracy 100.0%\n",
      "Epoch : 88 / Batch 2 : Loss : 0.035377729684114456 and Accuracy 98.0%\n",
      "Epoch : 88 / Batch 3 : Loss : 0.05627023056149483 and Accuracy 96.0%\n",
      "Epoch : 89 / Batch 0 : Loss : 0.00859387218952179 and Accuracy 100.0%\n",
      "Epoch : 89 / Batch 1 : Loss : 0.008690658956766129 and Accuracy 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 89 / Batch 2 : Loss : 0.0334029495716095 and Accuracy 100.0%\n",
      "Epoch : 89 / Batch 3 : Loss : 0.031197596341371536 and Accuracy 100.0%\n",
      "Epoch : 90 / Batch 0 : Loss : 0.010385798290371895 and Accuracy 100.0%\n",
      "Epoch : 90 / Batch 1 : Loss : 0.014985425397753716 and Accuracy 100.0%\n",
      "Epoch : 90 / Batch 2 : Loss : 0.10084781050682068 and Accuracy 94.0%\n",
      "Epoch : 90 / Batch 3 : Loss : 0.029816539958119392 and Accuracy 98.0%\n",
      "Epoch : 91 / Batch 0 : Loss : 0.04096484184265137 and Accuracy 98.0%\n",
      "Epoch : 91 / Batch 1 : Loss : 0.044017259031534195 and Accuracy 98.0%\n",
      "Epoch : 91 / Batch 2 : Loss : 0.008209840394556522 and Accuracy 100.0%\n",
      "Epoch : 91 / Batch 3 : Loss : 0.007058426272124052 and Accuracy 100.0%\n",
      "Epoch : 92 / Batch 0 : Loss : 0.04461418464779854 and Accuracy 98.0%\n",
      "Epoch : 92 / Batch 1 : Loss : 0.002366795437410474 and Accuracy 100.0%\n",
      "Epoch : 92 / Batch 2 : Loss : 0.10618069022893906 and Accuracy 94.0%\n",
      "Epoch : 92 / Batch 3 : Loss : 0.017850005999207497 and Accuracy 98.0%\n",
      "Epoch : 93 / Batch 0 : Loss : 0.01908583752810955 and Accuracy 98.0%\n",
      "Epoch : 93 / Batch 1 : Loss : 0.016453025862574577 and Accuracy 100.0%\n",
      "Epoch : 93 / Batch 2 : Loss : 0.11142454296350479 and Accuracy 92.0%\n",
      "Epoch : 93 / Batch 3 : Loss : 0.011618235148489475 and Accuracy 100.0%\n",
      "Epoch : 94 / Batch 0 : Loss : 0.04037066921591759 and Accuracy 98.0%\n",
      "Epoch : 94 / Batch 1 : Loss : 0.04979603737592697 and Accuracy 98.0%\n",
      "Epoch : 94 / Batch 2 : Loss : 0.05202062427997589 and Accuracy 98.0%\n",
      "Epoch : 94 / Batch 3 : Loss : 0.17153097689151764 and Accuracy 94.0%\n",
      "Epoch : 95 / Batch 0 : Loss : 0.036397386342287064 and Accuracy 96.0%\n",
      "Epoch : 95 / Batch 1 : Loss : 0.043877460062503815 and Accuracy 96.0%\n",
      "Epoch : 95 / Batch 2 : Loss : 0.037773314863443375 and Accuracy 98.0%\n",
      "Epoch : 95 / Batch 3 : Loss : 0.04203048720955849 and Accuracy 98.0%\n",
      "Epoch : 96 / Batch 0 : Loss : 0.10351265221834183 and Accuracy 94.0%\n",
      "Epoch : 96 / Batch 1 : Loss : 0.05197194963693619 and Accuracy 96.0%\n",
      "Epoch : 96 / Batch 2 : Loss : 0.02716664783656597 and Accuracy 100.0%\n",
      "Epoch : 96 / Batch 3 : Loss : 0.025628257542848587 and Accuracy 100.0%\n",
      "Epoch : 97 / Batch 0 : Loss : 0.04305754229426384 and Accuracy 98.0%\n",
      "Epoch : 97 / Batch 1 : Loss : 0.05230332911014557 and Accuracy 96.0%\n",
      "Epoch : 97 / Batch 2 : Loss : 0.05759437009692192 and Accuracy 98.0%\n",
      "Epoch : 97 / Batch 3 : Loss : 0.04476342722773552 and Accuracy 98.0%\n",
      "Epoch : 98 / Batch 0 : Loss : 0.02221549302339554 and Accuracy 98.0%\n",
      "Epoch : 98 / Batch 1 : Loss : 0.028850488364696503 and Accuracy 100.0%\n",
      "Epoch : 98 / Batch 2 : Loss : 0.024949513375759125 and Accuracy 98.0%\n",
      "Epoch : 98 / Batch 3 : Loss : 0.027969123795628548 and Accuracy 100.0%\n",
      "Epoch : 99 / Batch 0 : Loss : 0.030355999246239662 and Accuracy 100.0%\n",
      "Epoch : 99 / Batch 1 : Loss : 0.052551187574863434 and Accuracy 96.0%\n",
      "Epoch : 99 / Batch 2 : Loss : 0.041522037237882614 and Accuracy 98.0%\n",
      "Epoch : 99 / Batch 3 : Loss : 0.01798853650689125 and Accuracy 100.0%\n"
     ]
    }
   ],
   "source": [
    "for i in range(epoch): \n",
    "    for idx, (img, label) in enumerate(train_loader):\n",
    "        output = model(img)\n",
    "        #Checking the loss of the model.\n",
    "        loss = criterion(output, label)\n",
    "        #setting the gradients to zero \n",
    "        optimizer.zero_grad()\n",
    "        #backward propagation to recalculate the gradients.\n",
    "        loss.backward()\n",
    "        #updating the weights of the model.\n",
    "        optimizer.step()\n",
    "        #accuracy of the model \n",
    "        acc = accuracy(output, label)\n",
    "        errors.append(loss)\n",
    "        \n",
    "        print(f'Epoch : {i} / Batch {idx} : Loss : {loss} and Accuracy {acc*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#There are 4 batches and 100 epochs \n",
    "total_batches = [ i for i in range(400)]\n",
    "\n",
    "plt.plot(total_batches, errors, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter =>  49\n",
      "The test accuracy of the model is 96.0%\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "indie_acc = dict(zip(literal_label, [0 for i in range(10)]))\n",
    "sample = 0\n",
    "with torch.no_grad():\n",
    "    counter = 0\n",
    "    for x,y in test_loader:\n",
    "        outputs = model(x)\n",
    "        counter = counter + 1\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        new_total = torch.sum(torch.eq(preds, y)).item()\n",
    "        #Checking for the accuracy for each color.\n",
    "        for pred, label in zip(preds, y):\n",
    "            if (pred == label): \n",
    "                real_label = literal_label[pred]\n",
    "                indie_acc[real_label] = indie_acc[real_label] + 1 \n",
    "                counter = counter + 1\n",
    "#               print(counter)\n",
    "            \n",
    "        print(f'Counter =>  {counter}')\n",
    "        total = total + new_total\n",
    "        sample = sample + len(y)\n",
    "        acc = (total / sample)  * 100\n",
    "        print(f'The test accuracy of the model is {acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'black': 5,\n",
       " 'blue': 5,\n",
       " 'brown': 4,\n",
       " 'green': 5,\n",
       " 'grey': 5,\n",
       " 'orange': 5,\n",
       " 'red': 5,\n",
       " 'violet': 5,\n",
       " 'white': 5,\n",
       " 'yellow': 4}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indie_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above Only brown and yellow was incorrectly classified as once\n",
    "\n",
    "And the accuracy of the model is 96.0%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
